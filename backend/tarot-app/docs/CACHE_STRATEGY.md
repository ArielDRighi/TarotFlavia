# Cach√© de Interpretaciones - Estrategia y Plan de Migraci√≥n

## Estado Actual: Cach√© In-Memory (MVP)

La implementaci√≥n actual utiliza `@nestjs/cache-manager` con cach√© en memoria, que es suficiente para el MVP por las siguientes razones:

- ‚úÖ **Simplicidad**: No requiere infraestructura adicional
- ‚úÖ **Costo cero**: No hay costos de hosting para Redis
- ‚úÖ **Rendimiento**: Muy r√°pido para una sola instancia
- ‚úÖ **Configuraci√≥n m√≠nima**: Funciona out-of-the-box

### Estrategia Dual Actual

1. **Cach√© In-Memory** (TTL: 1 hora)

   - Datos est√°ticos: cartas, spreads, categor√≠as
   - Interpretaciones frecuentes
   - M√°ximo 200 items

2. **Cach√© en Base de Datos** (TTL: 30 d√≠as)
   - Interpretaciones completas persistentes
   - Reutilizaci√≥n entre instancias (si se escala)
   - An√°lisis de uso (hit_count, last_used_at)

## Cu√°ndo Migrar a Redis

### Indicadores para Considerar Redis:

#### 1. **Escalamiento Horizontal** ‚ö†Ô∏è CR√çTICO

- **Problema**: Con m√∫ltiples instancias del backend, cada una tiene su propio cach√© in-memory
- **Resultado**: Duplicaci√≥n innecesaria de llamadas a OpenAI
- **Soluci√≥n**: Redis como cach√© compartido entre instancias
- **Umbral**: Cuando tengas m√°s de 1 instancia del backend

#### 2. **Consumo Excesivo de RAM** ‚ö†Ô∏è IMPORTANTE

- **Problema**: El cach√© in-memory consume memoria del proceso Node.js
- **S√≠ntomas**:
  - RAM usage > 512MB para cach√©
  - OOM (Out of Memory) errors
  - Degradaci√≥n de performance general
- **Soluci√≥n**: Redis gestiona su propia memoria independientemente
- **Umbral**: Cuando el cach√© supere ~500MB

#### 3. **Tasa de Evicci√≥n Alta** üìä MODERADO

- **Problema**: Con l√≠mite de 200 items, las interpretaciones se eliminan prematuramente
- **S√≠ntomas**:
  - Cache hit rate < 40%
  - Interpretaciones populares siendo evictadas
- **Soluci√≥n**: Redis permite mayor capacidad de cach√©
- **Umbral**: Hit rate < 40% sostenido

#### 4. **Persistencia de Cach√© entre Reinicios** üîÑ NICE-TO-HAVE

- **Problema**: Reiniciar el servidor elimina todo el cach√© in-memory
- **Impacto**: Primera hora post-reinicio tiene muchos cache misses
- **Soluci√≥n**: Redis con persistencia RDB/AOF
- **Umbral**: Si los reinicios son frecuentes (CI/CD, scaling, etc.)

## Plan de Migraci√≥n a Redis

### Fase 1: Preparaci√≥n

```typescript
// 1. Instalar dependencias
npm install cache-manager-redis-store redis

// 2. Agregar variables de entorno
REDIS_HOST=localhost
REDIS_PORT=6379
REDIS_PASSWORD=your_password (opcional)
REDIS_TTL=3600 // 1 hora en segundos
```

### Fase 2: Configuraci√≥n

```typescript
// app.module.ts
import * as redisStore from 'cache-manager-redis-store';

@Module({
  imports: [
    CacheModule.register({
      isGlobal: true,
      store: redisStore,
      host: process.env.REDIS_HOST,
      port: parseInt(process.env.REDIS_PORT, 10),
      password: process.env.REDIS_PASSWORD,
      ttl: parseInt(process.env.REDIS_TTL, 10),
      max: 1000, // M√°s capacidad con Redis
    }),
    // ... otros imports
  ],
})
export class AppModule {}
```

### Fase 3: Docker Compose (Desarrollo)

```yaml
# docker-compose.yml
version: '3.8'
services:
  redis:
    image: redis:7-alpine
    ports:
      - '6379:6379'
    volumes:
      - redis-data:/data
    command: redis-server --appendonly yes

volumes:
  redis-data:
```

### Fase 4: Testing

1. **Probar conexi√≥n**:

```bash
redis-cli ping
# Debe responder: PONG
```

2. **Verificar keys**:

```bash
redis-cli keys "*"
```

3. **Monitorear en tiempo real**:

```bash
redis-cli monitor
```

### Fase 5: Producci√≥n

**Opciones de hosting:**

1. **AWS ElastiCache** (Recomendado para AWS)

   - Managed Redis
   - Backup autom√°tico
   - Alta disponibilidad
   - Costo: ~$15/mes (cache.t3.micro)

2. **Redis Cloud** (Multi-cloud)

   - Free tier: 30MB
   - Paid: desde $5/mes
   - Global replication

3. **DigitalOcean Managed Redis**

   - Desde $15/mes
   - Backups autom√°ticos

4. **Self-hosted** (En tu VPS)
   - Costo: Solo el VPS
   - Requiere mantenimiento manual

## Estrategia de Invalidaci√≥n de Cach√©

### 1. **Invalidaci√≥n por Tiempo (TTL)**

Ya implementado:

- In-memory: 1 hora
- Database: 30 d√≠as

### 2. **Invalidaci√≥n por Eventos** (Futuro)

```typescript
// Cuando se actualice significado de una carta
@Injectable()
export class CardsService {
  async updateCard(id: number, updateDto: UpdateCardDto) {
    await this.cardsRepository.update(id, updateDto);

    // Invalidar cach√©s que contengan esta carta
    await this.cacheService.invalidateCacheByCardId(id);
  }
}
```

### 3. **Invalidaci√≥n Selectiva**

```typescript
// InterpretationCacheService
async invalidateCacheByCardId(cardId: string): Promise<void> {
  // Buscar todos los cach√©s que contengan esta carta
  const affectedCaches = await this.cacheRepository
    .createQueryBuilder('cache')
    .where("cache.card_combination @> :card", {
      card: JSON.stringify([{ card_id: cardId }])
    })
    .getMany();

  // Eliminar de ambos cach√©s
  for (const cache of affectedCaches) {
    await this.cacheManager.del(cache.cache_key);
    await this.cacheRepository.delete(cache.id);
  }
}
```

### 4. **Invalidaci√≥n por Categor√≠a**

```typescript
async invalidateCacheByCategory(category: string): Promise<void> {
  // Limpiar cach√©s de una categor√≠a espec√≠fica
  await this.cacheRepository
    .createQueryBuilder()
    .delete()
    .where("question_hash LIKE :pattern", {
      pattern: `%${category}%`
    })
    .execute();
}
```

## Monitoreo y M√©tricas

### KPIs Actuales

```typescript
// Disponibles en GET /interpretations/admin/cache/stats
{
  "database": {
    "total": 150,           // Total de interpretaciones cacheadas
    "expired": 5,           // Cach√©s expirados (para limpieza)
    "avgHits": 3.2         // Promedio de reutilizaciones
  },
  "hitRate": {
    "percentage": 65.5,    // % de requests servidas desde cach√©
    "description": "65.50% of requests served from cache"
  }
}
```

### M√©tricas a Agregar con Redis

```typescript
// redis-cli info stats
{
  "keyspace_hits": 1000,     // Aciertos de cach√©
  "keyspace_misses": 200,    // Fallos de cach√©
  "evicted_keys": 50,        // Keys eliminadas por falta de memoria
  "expired_keys": 120,       // Keys expiradas naturalmente
  "memory_used": "45MB"      // Memoria consumida
}
```

## Estrategia de Rollback

Si Redis falla o hay problemas:

```typescript
// app.module.ts - Fallback a in-memory
CacheModule.register({
  isGlobal: true,
  store: process.env.USE_REDIS === 'true' ? redisStore : 'memory',
  // ... configuraci√≥n
});
```

## Recomendaciones

### Para MVP (Actual) ‚úÖ

- Mantener cach√© in-memory + DB
- Monitorear hit rate
- Optimizar TTLs seg√∫n uso real
- No invertir en Redis a√∫n

### Para Escalamiento (Futuro) üöÄ

- Implementar Redis cuando:
  - Escales a 2+ instancias, O
  - Hit rate < 40%, O
  - RAM usage > 500MB para cach√©
- Usar Redis Cloud para empezar (free tier)
- Migrar a managed service en producci√≥n

### Optimizaciones Adicionales üí°

1. **Cach√© de prompts**: Cachear prompts generados por spread/categor√≠a
2. **Partial cache**: Cachear significados de cartas individuales
3. **Cache warming**: Pre-poblar cach√© con combinaciones comunes
4. **Compression**: Comprimir interpretaciones largas antes de cachear

## Conclusi√≥n

**No necesitas Redis para MVP**, pero cuando escales horizontalmente o notes degradaci√≥n de performance, esta documentaci√≥n te guiar√° en la migraci√≥n. El sistema actual de doble cach√© (in-memory + DB) es robusto y suficiente para etapas tempranas.
