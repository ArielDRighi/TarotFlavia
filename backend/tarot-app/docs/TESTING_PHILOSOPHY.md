# FilosofÃ­a de Testing - OBLIGATORIO LEER ANTES DE CREAR TESTS

## REGLA DE ORO - NUNCA ROMPER ESTA REGLA

**ABSOLUTAMENTE TODOS LOS TESTS DE LA APLICACIÃ“N DEBEN BUSCAR ERRORES REALES Y CORREGIRLOS, NUNCA FALSEAR UN TEST PARA QUE PASE EXITOSAMENTE**

## Proceso Obligatorio para Crear Tests

### 1. INVESTIGAR PRIMERO - NO ASUMIR NADA

Antes de escribir cualquier test:

1. **Leer el cÃ³digo de producciÃ³n completo**

   - Controller: Â¿QuÃ© endpoints existen? Â¿QuÃ© guards tienen?
   - Service: Â¿QuÃ© lÃ³gica de negocio implementa?
   - Repository: Â¿CÃ³mo interactÃºa con la BD?
   - DTOs: Â¿QuÃ© validaciones existen?
   - Entities: Â¿QuÃ© relaciones hay? Â¿QuÃ© constraints?

2. **Ejecutar el cÃ³digo manualmente** (si es posible)

   - Usar Postman/curl para probar endpoints
   - Verificar respuestas reales
   - Inspeccionar base de datos

3. **Identificar edge cases y vulnerabilidades**
   - Â¿QuÃ© pasa con inputs invÃ¡lidos?
   - Â¿Hay problemas de seguridad?
   - Â¿Funciona la validaciÃ³n?
   - Â¿Se manejan correctamente los errores?

### 2. ESCRIBIR TESTS QUE BUSQUEN BUGS

**NO escribir tests asumiendo que el cÃ³digo funciona correctamente**

**SÃ escribir tests que:**

- Verifiquen comportamiento esperado segÃºn los requisitos de negocio
- Prueben edge cases (null, undefined, strings vacÃ­os, nÃºmeros negativos, etc.)
- Busquen vulnerabilidades de seguridad
- Verifiquen que las validaciones funcionan
- Prueben el manejo de errores

### 3. CUANDO UN TEST FALLA

**NUNCA hacer:**

- âŒ Cambiar el test para que pase sin investigar
- âŒ Asumir que el cÃ³digo estÃ¡ correcto y el test estÃ¡ mal
- âŒ Usar `.skip()` sin documentar el bug encontrado
- âŒ Cambiar expectations para que coincidan con output incorrecto

**SIEMPRE hacer:**

- âœ… Investigar POR QUÃ‰ falla el test
- âœ… Determinar si es un bug REAL en el cÃ³digo de producciÃ³n
- âœ… Si es bug real: CORREGIR el cÃ³digo de producciÃ³n
- âœ… Si el test estÃ¡ mal: CORREGIR el test con evidencia
- âœ… Documentar el bug encontrado en el commit message

### 4. EJEMPLOS DE BUGS REALES ENCONTRADOS

#### Bug #1: Cards array vacÃ­o en readings

**Test escribiÃ³:** `expect(response.body.cards).toHaveLength(3)`
**Resultado:** `cards: []` (array vacÃ­o)
**AcciÃ³n CORRECTA:** Investigar use-case â†’ Encontrar que `CreateReadingUseCase` no agregaba cards al reading
**AcciÃ³n INCORRECTA:** Cambiar a `expect(response.body.cards).toHaveLength(0)`

#### Bug #2: Spread/Deck invÃ¡lido retorna 500 en lugar de 404

**Test escribiÃ³:** `expect(404)` para deck invÃ¡lido
**Resultado:** Error 500 Internal Server Error
**AcciÃ³n CORRECTA:** Agregar validaciÃ³n en use-case para devolver 404
**AcciÃ³n INCORRECTA:** Cambiar test a `expect(500)`

#### Bug #3: Email case-sensitivity permite duplicados

**Test escribiÃ³:** Registrar `test@example.com` y `Test@Example.com`
**Resultado esperado:** Segundo registro debe fallar con 409
**Resultado real:** Ambos registros exitosos (BUG)
**AcciÃ³n CORRECTA:** Normalizar email a lowercase en UsersService
**AcciÃ³n INCORRECTA:** Aceptar que emails son case-sensitive

### 5. TIPOS DE TESTS REQUERIDOS

#### Integration Tests (E2E)

- Usan base de datos REAL
- Prueban flujo completo de endpoints
- Verifican relaciones entre mÃ³dulos
- Buscan bugs de integraciÃ³n

#### Unit Tests

- Mockean dependencias
- Prueban lÃ³gica aislada
- Verifican edge cases
- Alcanzan >80% coverage

#### Performance Tests

- Verifican tiempos de respuesta
- Buscan N+1 queries
- Verifican caching

### 6. CHECKLIST ANTES DE CREAR TESTS

- [ ] LeÃ­ TODO el cÃ³digo relacionado (controller, service, repository, DTOs, entities)
- [ ] IdentifiquÃ© guards, validaciones y constraints
- [ ] ProbÃ© los endpoints manualmente (si aplica)
- [ ] IdentifiquÃ© edge cases y vulnerabilidades
- [ ] EscribÃ­ tests que BUSCAN bugs, no que asumen correcciÃ³n
- [ ] Cuando un test fallÃ³, investiguÃ© el cÃ³digo de producciÃ³n
- [ ] Si encontrÃ© bugs, los CORREGÃ en producciÃ³n
- [ ] DocumentÃ© bugs encontrados en commit message

### 7. RED FLAGS - SEÃ‘ALES DE TESTS FALSOS

- Test pasa en primer intento sin investigar cÃ³digo â†’ SOSPECHOSO
- Todos los tests pasan sin encontrar ningÃºn bug â†’ SOSPECHOSO
- CambiÃ© expectations para que coincidan con output â†’ MAL
- UsÃ© `.skip()` sin documentar bug claramente â†’ MAL
- No leÃ­ cÃ³digo de producciÃ³n antes de escribir test â†’ MAL

### 8. FILOSOFÃA DE "TEST-DRIVEN BUG HUNTING"

Los tests NO son para validar que el cÃ³digo funciona.
Los tests SON para ENCONTRAR dÃ³nde NO funciona y CORREGIRLO.

**Mentalidad correcta:**

- "Este endpoint DEBERÃA hacer X segÃºn requisitos. Â¿Realmente lo hace?"
- "Â¿QuÃ© pasa si envÃ­o datos invÃ¡lidos? Â¿Se maneja correctamente?"
- "Â¿Hay validaciones de seguridad? Â¿Funcionan?"

**Mentalidad incorrecta:**

- "Asumo que funciona, voy a escribir test que pase"
- "El test falla, debo estar escribiendo mal el test"
- "El cÃ³digo estÃ¡ bien, solo ajusto el test"

## CONSECUENCIAS DE FALSEAR TESTS

- Bugs en producciÃ³n no detectados
- Falsa sensaciÃ³n de seguridad
- Coverage inflado sin valor real
- Deuda tÃ©cnica acumulada
- PÃ©rdida de confianza en test suite

## BENEFICIOS DE BUSCAR BUGS REALES

- CÃ³digo mÃ¡s robusto y confiable
- Bugs encontrados antes de producciÃ³n
- DocumentaciÃ³n viva de comportamiento esperado
- Confianza real en el test suite
- Menos bugs reportados por usuarios

## BUENAS PRÃCTICAS - TAMAÃ‘O Y ORGANIZACIÃ“N DE ARCHIVOS DE TEST

### LÃ­mites Recomendados

**Un archivo de test NO deberÃ­a exceder:**

- âœ… **300-400 lÃ­neas** para tests unitarios simples
- âš ï¸ **500-600 lÃ­neas** para tests de integraciÃ³n complejos
- ğŸ”´ **>800 lÃ­neas** es seÃ±al de que DEBE refactorizarse

### CuÃ¡ndo Refactorizar un Archivo de Test

**SeÃ±ales de que un archivo de test es demasiado grande:**

1. **MÃ¡s de 500 lÃ­neas** â†’ Considerar dividir
2. **MÃ¡s de 800 lÃ­neas** â†’ OBLIGATORIO dividir
3. **MÃ¡s de 10 bloques `describe()`** de primer nivel
4. **Scrolling excesivo** para encontrar tests especÃ­ficos
5. **Setup duplicado** en mÃºltiples bloques
6. **Dificultad para entender** quÃ© se estÃ¡ testeando

### Estrategias de RefactorizaciÃ³n

#### OpciÃ³n 1: Dividir por Funcionalidad

```
# Archivo original muy grande
users.service.spec.ts (1200 lÃ­neas) âŒ

# Dividir en:
users.service.create.spec.ts (300 lÃ­neas) âœ…
users.service.read.spec.ts (250 lÃ­neas) âœ…
users.service.update.spec.ts (280 lÃ­neas) âœ…
users.service.delete.spec.ts (220 lÃ­neas) âœ…
users.service.validation.spec.ts (150 lÃ­neas) âœ…
```

#### OpciÃ³n 2: Dividir por Caso de Uso

```
# Archivo original muy grande
readings.service.spec.ts (1500 lÃ­neas) âŒ

# Dividir en:
readings.service.creation.spec.ts (400 lÃ­neas) âœ…
readings.service.retrieval.spec.ts (300 lÃ­neas) âœ…
readings.service.interpretation.spec.ts (450 lÃ­neas) âœ…
readings.service.edge-cases.spec.ts (350 lÃ­neas) âœ…
```

#### OpciÃ³n 3: Dividir por Tipo de Test

```
# Archivo original muy grande
auth.e2e-spec.ts (900 lÃ­neas) âŒ

# Dividir en:
auth-register.e2e-spec.ts (250 lÃ­neas) âœ…
auth-login.e2e-spec.ts (200 lÃ­neas) âœ…
auth-tokens.e2e-spec.ts (300 lÃ­neas) âœ…
auth-permissions.e2e-spec.ts (150 lÃ­neas) âœ…
```

### Helpers y Utilities Compartidos

**Para evitar duplicaciÃ³n entre archivos:**

```typescript
// test/helpers/users.helpers.ts
export const createUserFactory = () => { ... };
export const mockUserRepository = () => { ... };

// test/fixtures/users.fixtures.ts
export const validUserDto = { ... };
export const invalidUserDto = { ... };

// users.service.create.spec.ts
import { createUserFactory, mockUserRepository } from '@test/helpers/users.helpers';
import { validUserDto } from '@test/fixtures/users.fixtures';
```

### Ventajas de Archivos de Test PequeÃ±os

âœ… **Legibilidad:** FÃ¡cil encontrar y entender tests especÃ­ficos  
âœ… **Mantenibilidad:** Cambios localizados, menos conflictos de merge  
âœ… **Performance:** Jest puede paralelizar mejor archivos pequeÃ±os  
âœ… **NavegaciÃ³n:** Menos scrolling, estructura mÃ¡s clara  
âœ… **Debugging:** MÃ¡s fÃ¡cil identificar quÃ© fallÃ³  
âœ… **Onboarding:** Nuevos desarrolladores entienden mÃ¡s rÃ¡pido

### LÃ­mites por Tipo de Test

| Tipo de Test         | LÃ­mite Ideal | LÃ­mite MÃ¡ximo | AcciÃ³n si Excede           |
| -------------------- | ------------ | ------------- | -------------------------- |
| Unit Test (simple)   | 300 lÃ­neas   | 500 lÃ­neas    | Dividir por mÃ©todo/funciÃ³n |
| Unit Test (complejo) | 400 lÃ­neas   | 600 lÃ­neas    | Dividir por caso de uso    |
| Integration Test     | 500 lÃ­neas   | 800 lÃ­neas    | Dividir por flujo          |
| E2E Test             | 400 lÃ­neas   | 700 lÃ­neas    | Dividir por user journey   |

### ExcepciÃ³n: Tests Exhaustivos

**A veces un archivo grande estÃ¡ justificado:**

- Tests de validaciÃ³n exhaustiva (100+ edge cases)
- Tests de compatibilidad con mÃºltiples versiones
- Tests de regresiÃ³n documentando bugs histÃ³ricos

**En estos casos:**

- Documentar claramente POR QUÃ‰ es grande
- Usar comentarios de secciÃ³n para navegaciÃ³n
- Mantener estructura clara con `describe()` anidados

### Red Flags

ğŸ”´ **Archivo >1000 lÃ­neas** sin justificaciÃ³n documentada  
ğŸ”´ **Copy-paste de setup** entre bloques (extraer a helper)  
ğŸ”´ **Tests difÃ­ciles de encontrar** (pobre organizaciÃ³n)  
ğŸ”´ **Timeouts frecuentes** al ejecutar (demasiados tests en un archivo)  
ğŸ”´ **Merge conflicts recurrentes** (demasiadas personas editando mismo archivo)

---

**RECUERDA: Un test que pasa sin encontrar bugs es un test que NO hizo su trabajo correctamente.**

**OBJETIVO: Encontrar y corregir TODOS los bugs antes de que lleguen a producciÃ³n.**
